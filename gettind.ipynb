{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7b5c843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f75f1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x11f6e7f70> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x11e56ff40> root_client=<openai.OpenAI object at 0x11e56f3a0> root_async_client=<openai.AsyncOpenAI object at 0x11f78d1b0> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********') stream_usage=True\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model=\"gpt-4o\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8760623",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=llm.invoke(\"What is generative AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49a4544d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Generative AI refers to a category of artificial intelligence techniques designed to generate new content or data that is similar to a given set of examples. This type of AI uses models like neural networks to produce text, images, music, code, or other types of content. Unlike traditional AI, which focuses more on analyzing data and making predictions, generative AI aims to create new data instances.\\n\\nSome key technologies and models associated with generative AI include:\\n\\n1. **Generative Adversarial Networks (GANs):** GANs consist of two neural networks, a generator and a discriminator, that are trained together. The generator tries to create data that mimics the real data, while the discriminator attempts to distinguish between real and generated data. Through this adversarial process, the generator improves its ability to produce realistic data.\\n\\n2. **Variational Autoencoders (VAEs):** VAEs are a type of generative model that captures the underlying structure of data and learns to encode it into a latent space. This latent space can then be sampled to generate new data instances.\\n\\n3. **Transformer-based Models:** Models like GPT (Generative Pre-trained Transformer) are specifically designed for generating text. These models are trained on large corpora of text and are capable of producing coherent and contextually relevant sentences, paragraphs, or entire articles.\\n\\nGenerative AI has a wide range of applications, including:\\n\\n- **Content Creation:** Automating the creation of text, images, videos, and music.\\n- **Design and Art:** Assisting artists and designers in generating creative variations and new concepts.\\n- **Data Augmentation:** Producing synthetic data to enhance training datasets for machine learning models.\\n- **Gaming and Virtual Worlds:** Creating realistic environments, characters, and dialogues.\\n- **Personalization:** Generating personalized content and experiences in marketing and customer service.\\n\\nOverall, generative AI holds significant potential for advancing creativity and efficiency across various domains, although it also raises questions about authenticity, ethics, and intellectual property.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 400, 'prompt_tokens': 13, 'total_tokens': 413, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_eb3c3cb84d', 'id': 'chatcmpl-CSckxt3YdjbSsk1omwqz6GsRLtvc4', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--057a9e6f-aeb6-4a3b-9220-3d132dc72ffc-0' usage_metadata={'input_tokens': 13, 'output_tokens': 400, 'total_tokens': 413, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3894b544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answers based on the questions'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Chatprompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer. Provide me answers based on the questions\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    "\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3561316b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Langsmith is a toolkit designed to enhance the development, testing, and monitoring of applications that utilize Large Language Models (LLMs). It was created by LangChain and focuses on improving the reliability and efficiency of language model-assisted applications.\\n\\nKey features of Langsmith include:\\n\\n1. **Feedback and Evaluation:** Langsmith allows developers to gather and analyze human feedback alongside automated evaluations, offering a comprehensive view of how a language model is performing in real-world applications.\\n\\n2. **Example Management:** Developers can organize and manage examples to facilitate emergency debugging, understand user interactions better, and pinpoint areas that need improvement.\\n\\n3. **Tracing Capabilities:** Langsmith's tracing feature aids in debugging by providing a detailed view of the sequence of operations and API calls within an application powered by LLMs.\\n\\n4. **Integration with LangChain:** As it is developed by LangChain, Langsmith deeply integrates with the existing LangChain ecosystem, providing users with streamlined workflows for their language model operations.\\n\\nOverall, Langsmith enables developers to create more robust and effective LLM applications by providing critical insights and tools for continuous development and improvement.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 221, 'prompt_tokens': 33, 'total_tokens': 254, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_eb3c3cb84d', 'id': 'chatcmpl-CScooI2N7FaXM1EOjTDH2AkgWvcib', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--4a8abece-e02f-46ea-9f3d-952aea8ef1d1-0' usage_metadata={'input_tokens': 33, 'output_tokens': 221, 'total_tokens': 254, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "## chain \n",
    "chain=prompt|llm\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93f9f88b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
